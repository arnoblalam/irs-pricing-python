{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import xlogy\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_obs=1000, n_periods=2, treatment_effect=2, heterogeneous=False, selection=False):\n",
    "    # Generate time periods\n",
    "    time = np.repeat([0, 1], n_obs // 2)\n",
    "    \n",
    "    # Generate treatment group\n",
    "    if selection:\n",
    "        # Add selection bias\n",
    "        z = np.random.normal(0, 1, n_obs)\n",
    "        prob_treatment = norm.cdf(z)\n",
    "        treatment = np.random.binomial(1, prob_treatment)\n",
    "    else:\n",
    "        treatment = np.random.binomial(1, 0.5, n_obs)\n",
    "    \n",
    "    # Generate covariates\n",
    "    X = np.random.normal(0, 1, (n_obs, 2))\n",
    "    \n",
    "    # Generate outcomes\n",
    "    epsilon = np.random.normal(0, 1, n_obs)\n",
    "    y = 1.0 + 2 * treatment + 3 * time\n",
    "    \n",
    "    if heterogeneous:\n",
    "        # Add heterogeneous treatment effects\n",
    "        y += treatment * time * (2 + 0.5 * X[:, 0] + 0.5 * X[:, 1])\n",
    "    else:\n",
    "        # Add homogeneous treatment effect\n",
    "        y += treatment_effect * treatment * time\n",
    "    \n",
    "    y += epsilon\n",
    "    \n",
    "    if selection:\n",
    "        # Add selection bias to outcome\n",
    "        y += 0.5 * z\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'y': y,\n",
    "        'time': time,\n",
    "        'treatment': treatment,\n",
    "        'X1': X[:, 0],\n",
    "        'X2': X[:, 1]\n",
    "    })\n",
    "    \n",
    "    if selection:\n",
    "        df['z'] = z\n",
    "    \n",
    "    # Create interaction terms\n",
    "    df['treatment_time'] = df['treatment'] * df['time']\n",
    "    df['treatment_time_X1'] = df['treatment_time'] * df['X1']\n",
    "    df['treatment_time_X2'] = df['treatment_time'] * df['X2']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def traditional_did(df):\n",
    "    X = sm.add_constant(df[['treatment', 'time', 'treatment_time']])\n",
    "    model = sm.OLS(df['y'], X).fit()\n",
    "    return model.params['treatment_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heterogeneous_did(df):\n",
    "    df['treatment_time_X1'] = df['treatment_time'] * df['X1']\n",
    "    df['treatment_time_X2'] = df['treatment_time'] * df['X2']\n",
    "    X = sm.add_constant(df[['treatment', 'time', 'treatment_time', 'X1', 'X2', 'treatment_time_X1', 'treatment_time_X2']])\n",
    "    model = sm.OLS(df['y'], X).fit()\n",
    "    return model.params['treatment_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def selection_correction_did(df):\n",
    "    # First stage: Probit model for treatment selection\n",
    "    probit_model = sm.Probit(df['treatment'], sm.add_constant(df[['z']])).fit()\n",
    "    \n",
    "    # Calculate Inverse Mills Ratio\n",
    "    df['imr'] = norm.pdf(probit_model.predict()) / norm.cdf(probit_model.predict())\n",
    "    \n",
    "    # Second stage: DiD with selection correction\n",
    "    df['treatment_time_X1'] = df['treatment_time'] * df['X1']\n",
    "    df['treatment_time_X2'] = df['treatment_time'] * df['X2']\n",
    "    X = sm.add_constant(df[['treatment', 'time', 'treatment_time', 'X1', 'X2', 'treatment_time_X1', 'treatment_time_X2', 'imr']])\n",
    "    model = sm.OLS(df['y'], X).fit()\n",
    "    return model.params['treatment_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gme_did(df, n_support=5):\n",
    "    # Prepare data\n",
    "    y = df['y'].values\n",
    "    X = sm.add_constant(df[['treatment', 'time', 'treatment_time', 'X1', 'X2', 'treatment_time_X1', 'treatment_time_X2']])\n",
    "    \n",
    "    n_obs, n_params = X.shape\n",
    "    \n",
    "    # Create support points for parameters and error terms\n",
    "    z_beta = np.linspace(-10, 10, n_support)\n",
    "    z_eps = np.linspace(-5, 5, n_support)\n",
    "    \n",
    "    # Define the objective function (negative entropy)\n",
    "    def objective(p):\n",
    "        p_beta = p[:n_params*n_support].reshape(n_params, n_support)\n",
    "        p_eps = p[n_params*n_support:].reshape(n_obs, n_support)\n",
    "        return np.sum(xlogy(p_beta, p_beta)) + np.sum(xlogy(p_eps, p_eps))\n",
    "    \n",
    "    # Define constraints\n",
    "    def constraint_mean(p):\n",
    "        p_beta = p[:n_params*n_support].reshape(n_params, n_support)\n",
    "        p_eps = p[n_params*n_support:].reshape(n_obs, n_support)\n",
    "        beta_hat = np.sum(z_beta * p_beta, axis=1)\n",
    "        eps_hat = np.sum(z_eps * p_eps, axis=1)\n",
    "        return y - np.dot(X, beta_hat) - eps_hat\n",
    "    \n",
    "    def constraint_sum_to_one(p):\n",
    "        return np.concatenate([\n",
    "            np.sum(p[:n_params*n_support].reshape(n_params, n_support), axis=1) - 1,\n",
    "            np.sum(p[n_params*n_support:].reshape(n_obs, n_support), axis=1) - 1\n",
    "        ])\n",
    "    \n",
    "    # Initial guess\n",
    "    p0 = np.full(n_params*n_support + n_obs*n_support, 1/(n_support))\n",
    "    \n",
    "    # Solve the optimization problem\n",
    "    result = minimize(\n",
    "        objective, p0,\n",
    "        method='SLSQP',\n",
    "        constraints=[\n",
    "            {'type': 'eq', 'fun': constraint_mean},\n",
    "            {'type': 'eq', 'fun': constraint_sum_to_one}\n",
    "        ],\n",
    "        options={'ftol': 1e-8, 'maxiter': 1000}\n",
    "    )\n",
    "    \n",
    "    # Extract the estimated parameters\n",
    "    p_beta_opt = result.x[:n_params*n_support].reshape(n_params, n_support)\n",
    "    beta_hat = np.sum(z_beta * p_beta_opt, axis=1)\n",
    "    \n",
    "    # Return the treatment effect (coefficient on 'treatment_time')\n",
    "    return beta_hat[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gme_did_selection(df, n_support=5):\n",
    "    # First stage: Probit model for treatment selection\n",
    "    probit_model = sm.Probit(df['treatment'], sm.add_constant(df[['z']])).fit()\n",
    "    \n",
    "    # Calculate Inverse Mills Ratio\n",
    "    df['imr'] = norm.pdf(probit_model.predict()) / norm.cdf(probit_model.predict())\n",
    "    \n",
    "    # Prepare data\n",
    "    y = df['y'].values\n",
    "    X = sm.add_constant(df[['treatment', 'time', 'treatment_time', 'X1', 'X2', 'treatment_time_X1', 'treatment_time_X2', 'imr']])\n",
    "    \n",
    "    n_obs, n_params = X.shape\n",
    "    \n",
    "    # Create support points for parameters and error terms\n",
    "    z_beta = np.linspace(-10, 10, n_support)\n",
    "    z_eps = np.linspace(-5, 5, n_support)\n",
    "    \n",
    "    # Define the objective function (negative entropy)\n",
    "    def objective(p):\n",
    "        p_beta = p[:n_params*n_support].reshape(n_params, n_support)\n",
    "        p_eps = p[n_params*n_support:].reshape(n_obs, n_support)\n",
    "        return np.sum(xlogy(p_beta, p_beta)) + np.sum(xlogy(p_eps, p_eps))\n",
    "    \n",
    "    # Define constraints\n",
    "    def constraint_mean(p):\n",
    "        p_beta = p[:n_params*n_support].reshape(n_params, n_support)\n",
    "        p_eps = p[n_params*n_support:].reshape(n_obs, n_support)\n",
    "        beta_hat = np.sum(z_beta * p_beta, axis=1)\n",
    "        eps_hat = np.sum(z_eps * p_eps, axis=1)\n",
    "        return y - np.dot(X, beta_hat) - eps_hat\n",
    "    \n",
    "    def constraint_sum_to_one(p):\n",
    "        return np.concatenate([\n",
    "            np.sum(p[:n_params*n_support].reshape(n_params, n_support), axis=1) - 1,\n",
    "            np.sum(p[n_params*n_support:].reshape(n_obs, n_support), axis=1) - 1\n",
    "        ])\n",
    "    \n",
    "    # Initial guess\n",
    "    p0 = np.full(n_params*n_support + n_obs*n_support, 1/(n_support))\n",
    "    \n",
    "    # Solve the optimization problem\n",
    "    result = minimize(\n",
    "        objective, p0,\n",
    "        method='SLSQP',\n",
    "        constraints=[\n",
    "            {'type': 'eq', 'fun': constraint_mean},\n",
    "            {'type': 'eq', 'fun': constraint_sum_to_one}\n",
    "        ],\n",
    "        options={'ftol': 1e-8, 'maxiter': 1000}\n",
    "    )\n",
    "    \n",
    "    # Extract the estimated parameters\n",
    "    p_beta_opt = result.x[:n_params*n_support].reshape(n_params, n_support)\n",
    "    beta_hat = np.sum(z_beta * p_beta_opt, axis=1)\n",
    "    \n",
    "    # Return the treatment effect (coefficient on 'treatment_time')\n",
    "    return beta_hat[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(n_simulations=1000, n_obs=1000, treatment_effect=2):\n",
    "    results = {\n",
    "        'traditional': [],\n",
    "        'heterogeneous': [],\n",
    "        'selection': [],\n",
    "        'gme': [],\n",
    "        'gme_selection': []\n",
    "    }\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # Base case\n",
    "        df_base = generate_data(n_obs=n_obs, treatment_effect=treatment_effect)\n",
    "        results['traditional'].append(traditional_did(df_base))\n",
    "        results['gme'].append(gme_did(df_base))\n",
    "        \n",
    "        # Heterogeneous treatment effects\n",
    "        df_hetero = generate_data(n_obs=n_obs, treatment_effect=treatment_effect, heterogeneous=True)\n",
    "        results['heterogeneous'].append(heterogeneous_did(df_hetero))\n",
    "        \n",
    "        # Selection effects\n",
    "        df_selection = generate_data(n_obs=n_obs, treatment_effect=treatment_effect, heterogeneous=True, selection=True)\n",
    "        results['selection'].append(selection_correction_did(df_selection))\n",
    "        results['gme_selection'].append(gme_did_selection(df_selection))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run simulation\n",
    "sim_results = run_simulation()\n",
    "\n",
    "# Print results\n",
    "for method, estimates in sim_results.items():\n",
    "    print(f\"{method.capitalize()} DiD:\")\n",
    "    print(f\"  Mean estimate: {np.mean(estimates):.4f}\")\n",
    "    print(f\"  Standard deviation: {np.std(estimates):.4f}\")\n",
    "    print(f\"  95% CI: ({np.percentile(estimates, 2.5):.4f}, {np.percentile(estimates, 97.5):.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print results\n",
    "for method, estimates in sim_results.items():\n",
    "    print(f\"{method.capitalize()} DiD:\")\n",
    "    print(f\"  Mean estimate: {np.mean(estimates):.4f}\")\n",
    "    print(f\"  Standard deviation: {np.std(estimates):.4f}\")\n",
    "    print(f\"  95% CI: ({np.percentile(estimates, 2.5):.4f}, {np.percentile(estimates, 97.5):.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(n_simulations=1000, n_obs=1000, treatment_effect=2):\n",
    "    results = {\n",
    "        'traditional': [],\n",
    "        'heterogeneous': [],\n",
    "        'selection': [],\n",
    "        'gme': []\n",
    "    }\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # Base case\n",
    "        df_base = generate_data(n_obs=n_obs, treatment_effect=treatment_effect)\n",
    "        results['traditional'].append(traditional_did(df_base))\n",
    "        results['gme'].append(gme_did(df_base))\n",
    "        \n",
    "        # Heterogeneous treatment effects\n",
    "        df_hetero = generate_data(n_obs=n_obs, treatment_effect=treatment_effect, heterogeneous=True)\n",
    "        results['heterogeneous'].append(heterogeneous_did(df_hetero))\n",
    "        \n",
    "        # Selection effects\n",
    "        df_selection = generate_data(n_obs=n_obs, treatment_effect=treatment_effect, heterogeneous=True, selection=True)\n",
    "        results['selection'].append(selection_correction_did(df_selection))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run simulation\n",
    "sim_results = run_simulation(n_simulations=100)  # Reduced number of simulations for quicker execution\n",
    "\n",
    "# Print results\n",
    "for method, estimates in sim_results.items():\n",
    "    print(f\"{method.capitalize()} DiD:\")\n",
    "    print(f\"  Mean estimate: {np.mean(estimates):.4f}\")\n",
    "    print(f\"  Standard deviation: {np.std(estimates):.4f}\")\n",
    "    print(f\"  95% CI: ({np.percentile(estimates, 2.5):.4f}, {np.percentile(estimates, 97.5):.4f})\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
