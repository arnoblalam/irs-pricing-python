{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility notebook\n",
    "This notebook explores realized volatility in the interst rate swap market for USD and CAD contracts around the time of the implementation of the Dodd-Frank Clearing Mandate.  The notebook proceeds as follows:\n",
    "- Load transaction level data for USD and CAD swaps contracts\n",
    "- Filter data for the appropriate inclusion conditions\n",
    "    - Tenors of 2-year, 5-year and 10-year\n",
    "    - References CDOR or LIBOR as the reference rate\n",
    "    - Currency is USD or CAD\n",
    "    - Trade Time is not on a Saturday, Sunday or holiday\n",
    "    - Code is 'TR' (trade)\n",
    "    - Type is 'IRS-FIX-FLOAT'\n",
    "- Calculate the realized volatility for USD and CAD contracts\n",
    "    - If contracts are specified in basis points, it is divided by 100 to express\n",
    "    rates as percentages\n",
    "    - A column for 'Categorical Trade Time' is calculated.\n",
    "    8:00 AM - 10:59 - morning\n",
    "    11:00 AM - 13:59 - mid-day\n",
    "    14:00 - 17:00 - afternoon\n",
    "    17:00 - 07:59 - off hours\n",
    "    - The log of the fixed rate is calculated\n",
    "    - The data are grouped by currency, date, categorical trade time and tenor\n",
    "    - The realized return as the first difference of the log fixed rate\n",
    "    - The volatility is calculated as the standard deviation of the realized\n",
    "    return\n",
    "-  Check if there are differences-in-differences before and after the implementation of the Clearing Mandate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/volatility/combined_trade_data.xlsx')\n",
    "# Convert 'Effective' and 'Maturity' columns to datetime format\n",
    "data['Effective'] = pd.to_datetime(data['Effective'])\n",
    "data['Maturity'] = pd.to_datetime(data['Maturity'])\n",
    "data['Trade Time'] = pd.to_datetime(data['Trade Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some additional columns\n",
    "data['Trade Date'] = data['Trade Time'].dt.date\n",
    "# Log price\n",
    "data['log_rate_1'] = data['Rate 1'].apply(lambda x: log(x) if x > 0 else None)\n",
    "def categorize_trade_time(time):\n",
    "    if time.hour >= 8 and time.hour < 11:\n",
    "        return 'morning'\n",
    "    elif time.hour >= 11 and time.hour < 14:\n",
    "        return 'mid day'\n",
    "    elif time.hour >=  14 and time.hour < 17:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'off hours'\n",
    "    \n",
    "data['trade_time_categorical'] = data['Trade Time'].apply(categorize_trade_time)\n",
    "data['Grp'] = data['Curr'].apply(lambda x: 1 if x == 'USD' \n",
    "                                 else (0 if x == 'CAD' else -1))\n",
    "data['Grp'] = data['Grp'].astype(int)\n",
    "\n",
    "# Define a function to check if the trade date falls within the specified periods\n",
    "def in_period(trade_date):\n",
    "    # Convert the trade date to string format for comparison\n",
    "    date_str = trade_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Define the date ranges in string format for 2013\n",
    "    ranges = [\n",
    "        ('2013-03-11', '2013-03-22'),\n",
    "        ('2013-06-10', '2013-06-21'),\n",
    "        ('2013-09-09', '2013-09-20'),\n",
    "    ]\n",
    "    \n",
    "    # Check if the date string falls within any of the ranges\n",
    "    return any(start <= date_str <= end for start, end in ranges)\n",
    "\n",
    "# Apply the function to create the new 'period' column\n",
    "data['period'] = data['Trade Time'].apply(lambda x: 1 if in_period(x) else 0)\n",
    "\n",
    "data['interaction'] = data['Grp'] * data['period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter for the stuff I want\n",
    "data_filtered = data[(data['Type'] == 'IRS Fix-Float') &\n",
    "     (data['CD'] == 'TR') &\n",
    "     ((data['Leg 2'] == 'USD-LIBOR-BBA') | (data['Leg 2'] == 'CAD-BA-CDOR')) &\n",
    "     ((data['Curr'] == 'USD') | (data['Curr'] == 'CAD')) &\n",
    "     (data['Trade Time'].dt.dayofweek < 5) &\n",
    "     (data['Trade Time'].dt.date != '2013-09-02') &\n",
    "     (data['Trade Time'].dt.date != '2013-05-27') &\n",
    "     (data['T'].isin(['1Y', '2Y', '3Y', '4Y', '5Y', '6Y', '7Y', '8Y', '9Y', '10Y', '15Y', '30Y']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v2/2g59sj7s7qbcgl_0l5zkx1gm0000gn/T/ipykernel_41195/1660616700.py:1: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  data_filtered = data_filtered.sort_values(by=['Curr', 'T', 'Trade Date', 'Trade Time']) \\\n"
     ]
    }
   ],
   "source": [
    "data_filtered = data_filtered.sort_values(by=['Curr', 'T', 'Trade Date', 'Trade Time']) \\\n",
    "                             .groupby(['Curr', 'T', 'Trade Date']) \\\n",
    "                             .apply(lambda x: x.assign(return_1=x['log_rate_1'].diff())) \\\n",
    "                             .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Curr', 'T', and 'Trade Date', then calculate the standard deviation of 'return_1'\n",
    "new_data = data_filtered.groupby(['Curr', 'T', 'Trade Date'])['return_1'].std().reset_index()\n",
    "\n",
    "# Rename the column containing the standard deviation to 'std_return_1'\n",
    "new_data = new_data.rename(columns={'return_1': 'std_return_1'})\n",
    "\n",
    "new_data['Grp'] = new_data['Curr'].apply(lambda x: 1 if x == 'USD' \n",
    "                                 else (0 if x == 'CAD' else -1))\n",
    "new_data['period'] = new_data['Trade Date'].apply(lambda x: 1 if in_period(x) else 0)\n",
    "new_data['interaction'] = new_data['Grp'] * new_data['period']\n",
    "\n",
    "\n",
    "new_data.to_csv('data/volatility/irs_fix_float_volatility.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           std_return_1   R-squared:                       0.117\n",
      "Model:                            OLS   Adj. R-squared:                  0.115\n",
      "Method:                 Least Squares   F-statistic:                     40.86\n",
      "Date:                Sun, 07 Apr 2024   Prob (F-statistic):           8.55e-25\n",
      "Time:                        21:09:12   Log-Likelihood:                -350.71\n",
      "No. Observations:                 925   AIC:                             709.4\n",
      "Df Residuals:                     921   BIC:                             728.7\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           0.1270      0.033      3.812      0.000       0.062       0.192\n",
      "period         -0.0134      0.047     -0.287      0.774      -0.105       0.078\n",
      "Grp             0.3009      0.038      7.818      0.000       0.225       0.376\n",
      "interaction    -0.0072      0.054     -0.134      0.893      -0.113       0.098\n",
      "==============================================================================\n",
      "Omnibus:                      300.238   Durbin-Watson:                   0.843\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1059.963\n",
      "Skew:                           1.543   Prob(JB):                    6.79e-231\n",
      "Kurtosis:                       7.240   Cond. No.                         10.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = new_data[['period', 'Grp', 'interaction']]\n",
    "X = sm.add_constant(X)  # Adds a constant term to the predictors\n",
    "Y = new_data['std_return_1']\n",
    "\n",
    "model = sm.OLS(Y, X, missing='drop').fit()\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
