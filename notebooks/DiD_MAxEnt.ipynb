{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Step 1: Simulate Data\n",
    "# --------------------------\n",
    "\n",
    "np.random.seed(123)\n",
    "N = 200\n",
    "N_treat = N // 2\n",
    "N_control = N - N_treat\n",
    "\n",
    "trend = 1.0\n",
    "treatment_effect = 2.0\n",
    "\n",
    "Y_treat_pre = np.random.normal(10, 1, N_treat)\n",
    "Y_control_pre = np.random.normal(10, 1, N_control)\n",
    "Y_treat_post = np.random.normal(10 + trend + treatment_effect, 1, N_treat)\n",
    "Y_control_post = np.random.normal(10 + trend, 1, N_control)\n",
    "\n",
    "mean_treat_pre = Y_treat_pre.mean()\n",
    "mean_treat_post = Y_treat_post.mean()\n",
    "mean_control_pre = Y_control_pre.mean()\n",
    "mean_control_post = Y_control_post.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Step 2: Set up Problem\n",
    "# --------------------------\n",
    "M = 5\n",
    "min_val = min(Y_treat_pre.min(), Y_control_pre.min(), Y_treat_post.min(), Y_control_post.min()) - 1\n",
    "max_val = max(Y_treat_pre.max(), Y_control_pre.max(), Y_treat_post.max(), Y_control_post.max()) + 1\n",
    "support = np.linspace(min_val, max_val, M)\n",
    "\n",
    "# We'll have 4 distributions: T_pre, T_post, C_pre, C_post\n",
    "# Each distribution has M probabilities. We'll store them in a single vector:\n",
    "# p = [p_treat_pre, p_treat_post, p_control_pre, p_control_post]\n",
    "# Dimension of p is 4*M = 20 (if M=5).\n",
    "\n",
    "# Indices:\n",
    "def idx(dist_name):\n",
    "    # Helper to get slice indices\n",
    "    # dist_name can be 'Tpre', 'Tpost', 'Cpre', 'Cpost'\n",
    "    dist_map = {\n",
    "        'Tpre': 0,\n",
    "        'Tpost': 1,\n",
    "        'Cpre': 2,\n",
    "        'Cpost': 3\n",
    "    }\n",
    "    base = dist_map[dist_name] * M\n",
    "    return slice(base, base+M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Step 3: Objective and Constraints\n",
    "# --------------------------\n",
    "\n",
    "def total_entropy(p):\n",
    "    # Entropy = -sum p_i log p_i\n",
    "    # total entropy is sum of entropy for each distribution\n",
    "    # Add a small epsilon inside the log to avoid log(0)\n",
    "    eps = 1e-15\n",
    "    return -np.sum(p * np.log(p + eps))\n",
    "\n",
    "# We want to maximize entropy => minimize negative entropy\n",
    "def objective(p):\n",
    "    return -total_entropy(p)  # we minimize the negative of total entropy\n",
    "\n",
    "# Constraints:\n",
    "# 1) Each distribution sums to 1\n",
    "def constraint_sum(p, dist_name):\n",
    "    return np.sum(p[idx(dist_name)]) - 1.0\n",
    "\n",
    "# 2) Moment matching constraints\n",
    "def constraint_moment(p, dist_name, observed_mean):\n",
    "    return np.sum(p[idx(dist_name)] * support) - observed_mean\n",
    "\n",
    "# We'll provide constraints as dictionaries for scipy minimize\n",
    "cons = []\n",
    "# Sum-to-one constraints\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_sum(p, 'Tpre')})\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_sum(p, 'Tpost')})\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_sum(p, 'Cpre')})\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_sum(p, 'Cpost')})\n",
    "\n",
    "# Moment constraints\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_moment(p, 'Tpre', mean_treat_pre)})\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_moment(p, 'Tpost', mean_treat_post)})\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_moment(p, 'Cpre', mean_control_pre)})\n",
    "cons.append({'type': 'eq', 'fun': lambda p: constraint_moment(p, 'Cpost', mean_control_post)})\n",
    "\n",
    "# Initial guess: uniform distributions\n",
    "p0 = np.ones(4*M) / M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# Step 4: Solve the Problem using SLSQP\n",
    "# --------------------------\n",
    "res = minimize(objective, p0, constraints=cons, method='SLSQP', options={'ftol':1e-9, 'disp':True})\n",
    "\n",
    "print(\"Optimization Status:\", res.success)\n",
    "print(\"Message:\", res.message)\n",
    "print(\"Optimal value (negative total entropy):\", res.fun)\n",
    "\n",
    "p_opt = res.x\n",
    "\n",
    "# Extract each distribution\n",
    "p_treat_pre_val = p_opt[idx('Tpre')]\n",
    "p_treat_post_val = p_opt[idx('Tpost')]\n",
    "p_control_pre_val = p_opt[idx('Cpre')]\n",
    "p_control_post_val = p_opt[idx('Cpost')]\n",
    "\n",
    "# Check constraints\n",
    "print(\"\\nCheck distribution sums:\")\n",
    "print(\"Tpre sum:\", p_treat_pre_val.sum())\n",
    "print(\"Tpost sum:\", p_treat_post_val.sum())\n",
    "print(\"Cpre sum:\", p_control_pre_val.sum())\n",
    "print(\"Cpost sum:\", p_control_post_val.sum())\n",
    "\n",
    "print(\"\\nCheck expected values:\")\n",
    "print(\"Tpre expected:\", np.sum(p_treat_pre_val*support), \"Observed:\", mean_treat_pre)\n",
    "print(\"Tpost expected:\", np.sum(p_treat_post_val*support), \"Observed:\", mean_treat_post)\n",
    "print(\"Cpre expected:\", np.sum(p_control_pre_val*support), \"Observed:\", mean_control_pre)\n",
    "print(\"Cpost expected:\", np.sum(p_control_post_val*support), \"Observed:\", mean_control_post)\n",
    "\n",
    "# Compute a DID-like estimate from the distributions:\n",
    "did_est = (np.sum(p_treat_post_val * support) - np.sum(p_treat_pre_val * support)) - \\\n",
    "          (np.sum(p_control_post_val * support) - np.sum(p_control_pre_val * support))\n",
    "\n",
    "print(\"\\nDID estimate from GME distributions:\", did_est)\n",
    "\n",
    "print(\"\\nDistributions:\")\n",
    "print(\"Tpre:\", p_treat_pre_val)\n",
    "print(\"Tpost:\", p_treat_post_val)\n",
    "print(\"Cpre:\", p_control_pre_val)\n",
    "print(\"Cpost:\", p_control_post_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Step 2: Combine Data into a Single Dataset\n",
    "# --------------------------\n",
    "# Let's assign group and period indicators:\n",
    "# Treat: 1 for treated units, 0 for control units\n",
    "# Post: 1 for post-treatment period, 0 for pre-treatment period\n",
    "\n",
    "# Pre-period data\n",
    "data_treat_pre = np.column_stack([\n",
    "    Y_treat_pre, \n",
    "    np.ones(N_treat),     # Treat=1\n",
    "    np.zeros(N_treat)     # Post=0\n",
    "])\n",
    "\n",
    "data_control_pre = np.column_stack([\n",
    "    Y_control_pre,\n",
    "    np.zeros(N_control),  # Treat=0\n",
    "    np.zeros(N_control)   # Post=0\n",
    "])\n",
    "\n",
    "# Post-period data\n",
    "data_treat_post = np.column_stack([\n",
    "    Y_treat_post,\n",
    "    np.ones(N_treat),     # Treat=1\n",
    "    np.ones(N_treat)      # Post=1\n",
    "])\n",
    "\n",
    "data_control_post = np.column_stack([\n",
    "    Y_control_post,\n",
    "    np.zeros(N_control),  # Treat=0\n",
    "    np.ones(N_control)    # Post=1\n",
    "])\n",
    "\n",
    "# Stack all together: columns: [Y, Treat, Post]\n",
    "data = np.vstack([data_treat_pre, data_control_pre, data_treat_post, data_control_post])\n",
    "\n",
    "Y = data[:,0]\n",
    "Treat = data[:,1]\n",
    "Post = data[:,2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
