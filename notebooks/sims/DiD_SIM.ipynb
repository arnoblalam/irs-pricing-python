{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIDEstimator:\n",
    "    def __init__(self, Y, D, T, X, W):\n",
    "        self.Y = Y\n",
    "        self.D = D\n",
    "        self.T = T\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.epsilon = 1e-10  # Small value to avoid numerical instability\n",
    "\n",
    "    def probit(self, W, params):\n",
    "        return norm.cdf(np.dot(W, params))\n",
    "    \n",
    "    def log_likelihood(self, params):\n",
    "        p = np.clip(self.probit(self.W, params), self.epsilon, 1 - self.epsilon)\n",
    "        return -np.sum(self.D * np.log(p) + (1 - self.D) * np.log(1 - p))\n",
    "    \n",
    "    def estimate_selection(self):\n",
    "        initial_params = np.zeros(self.W.shape[1])\n",
    "        result = minimize(self.log_likelihood, initial_params, method='BFGS')\n",
    "        return result.x\n",
    "    \n",
    "    def inverse_mills_ratio(self, W, params):\n",
    "        z = np.dot(W, params)\n",
    "        return norm.pdf(z) / (norm.cdf(z) + self.epsilon)\n",
    "    \n",
    "    def estimate_did(self):\n",
    "        # First stage: Estimate selection equation\n",
    "        selection_params = self.estimate_selection()\n",
    "        \n",
    "        # Compute Inverse Mills Ratio\n",
    "        imr = self.inverse_mills_ratio(self.W, selection_params)\n",
    "        \n",
    "        # Augment X with IMR\n",
    "        X_augmented = np.column_stack((self.X, imr))\n",
    "        \n",
    "        # Second stage: Estimate DiD model\n",
    "        DT = self.D * self.T\n",
    "        X_full = np.column_stack((np.ones_like(self.D), self.D, self.T, DT, X_augmented))\n",
    "        \n",
    "        # OLS estimation\n",
    "        beta = np.linalg.inv(X_full.T @ X_full) @ X_full.T @ self.Y\n",
    "        \n",
    "        # Compute standard errors (simplified, ignoring the first stage estimation)\n",
    "        residuals = self.Y - X_full @ beta\n",
    "        sigma2 = np.mean(residuals**2)\n",
    "        var_beta = sigma2 * np.linalg.inv(X_full.T @ X_full)\n",
    "        se_beta = np.sqrt(np.diag(var_beta))\n",
    "        \n",
    "        return beta, se_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to simulate data\n",
    "def simulate_data(n_samples, n_covariates, treatment_effect, selection_strength):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Covariates\n",
    "    X = np.random.randn(n_samples, n_covariates)\n",
    "    W = np.column_stack((np.ones(n_samples), X))\n",
    "    \n",
    "    # Treatment assignment (selection equation)\n",
    "    selection_params = np.random.randn(W.shape[1]) * selection_strength\n",
    "    p_treatment = norm.cdf(np.dot(W, selection_params))\n",
    "    D = (np.random.rand(n_samples) < p_treatment).astype(int)\n",
    "    \n",
    "    # Time periods\n",
    "    T = np.random.binomial(1, 0.5, n_samples)\n",
    "    \n",
    "    # Outcome\n",
    "    epsilon = np.random.randn(n_samples)\n",
    "    Y = 1 + 0.5 * D + 0.5 * T + treatment_effect * D * T + np.dot(X, np.random.randn(n_covariates)) + epsilon\n",
    "    \n",
    "    return Y, D, T, X, W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate data\n",
    "n_samples = 10000\n",
    "n_covariates = 3\n",
    "true_treatment_effect = 2\n",
    "selection_strength = 0.5\n",
    "\n",
    "Y, D, T, X, W = simulate_data(n_samples, n_covariates, true_treatment_effect, selection_strength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estimate DiD\n",
    "estimator = DIDEstimator(Y, D, T, X, W)\n",
    "beta, se_beta = estimator.estimate_did()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.3956 (SE: 0.4710)\n",
      "D: 0.4683 (SE: 0.0367)\n",
      "T: 0.4936 (SE: 0.0226)\n",
      "D*T (Treatment Effect): 2.0384 (SE: 0.0502)\n",
      "X1: 0.4097 (SE: 0.1280)\n",
      "X2: -0.3348 (SE: 0.0731)\n",
      "X3: -0.2260 (SE: 0.0207)\n",
      "IMR: -0.2553 (SE: 0.3079)\n",
      "\n",
      "True Treatment Effect: 2\n",
      "Estimated Treatment Effect: 2.0384 (SE: 0.0502)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print results\n",
    "param_names = ['Intercept', 'D', 'T', 'D*T (Treatment Effect)'] + [f'X{i+1}' for i in range(n_covariates)] + ['IMR']\n",
    "for name, b, se in zip(param_names, beta, se_beta):\n",
    "    print(f\"{name}: {b:.4f} (SE: {se:.4f})\")\n",
    "\n",
    "print(f\"\\nTrue Treatment Effect: {true_treatment_effect}\")\n",
    "print(f\"Estimated Treatment Effect: {beta[3]:.4f} (SE: {se_beta[3]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
